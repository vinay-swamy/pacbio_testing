{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix , roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import pathlib\n",
    "import glob\n",
    "tf.test.is_gpu_available()\n",
    "os.chdir('/data/swamyvs/pacbio_testing/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataObj:\n",
    "    def __init__(self, X_df, labs,kmer_size, one_label, zero_label, y_format='tf'):\n",
    "        positive_cases=['all', 'stringtie-pacbio', 'scallop-pacbio']\n",
    "        X_df_labeled=pd.merge(left=labs, right=X_df, left_on='transcript_id', right_on='transcript_id')\n",
    "        X_data=np.asarray(X_df_labeled.iloc[:,3:])#drop the first 3 columns\n",
    "        Y_vec=np.asarray(X_df_labeled['target_label'])\n",
    "        self.Y_origin=X_df_labeled.iloc[:,:3]\n",
    "        self.vec_y=Y_vec\n",
    "        \n",
    "        X_train, self.X_val, Y_train_labs, Y_val_labs= train_test_split(X_data,labs,test_size=.2, random_state=42, stratify=Y_vec)\n",
    "        self.X_train, self.X_test, Y_train_labs, Y_test_labs=train_test_split(X_train,Y_train_labs,test_size=.2, \n",
    "                                                                                  random_state=42,stratify=Y_train_labs['target_label'])\n",
    "\n",
    "        if y_format == 'tf':\n",
    "            self.Y_val=to_categorical(Y_val_labs['target_label'])\n",
    "            self.Y_train=to_categorical(Y_train_labs['target_label'])\n",
    "            self.Y_test=to_categorical(Y_test_labs['target_label'])\n",
    "        else:\n",
    "            self.Y_val=np.asarray(Y_val_labs['target_label'])\n",
    "            self.Y_train=np.asarray(Y_train_labs['target_label'])\n",
    "            self.Y_test=np.asarray(Y_test_labs['target_label'])\n",
    "            \n",
    "        self.Y_val_labs=Y_val_labs[['transcript_id','intersection_case']] \n",
    "        self.Y_train_labs=Y_train_labs[['transcript_id','intersection_case']]\n",
    "        self.Y_test_labs=Y_test_labs[['transcript_id','intersection_case']]\n",
    "            \n",
    "        self.y_format=y_format\n",
    "        self.one_label=one_label\n",
    "        self.zero_label=zero_label\n",
    "    def summary(self):\n",
    "        tr_len=len(self.X_train)\n",
    "        ts_len=len(self.X_test)\n",
    "        v_len= len(self.X_val)\n",
    "        print(f'Training size: {tr_len}\\nvalidation size: {v_len}\\ntesting size: {ts_len}')\n",
    "        print(f'{self.one_label} count: {np.count_nonzero(self.vec_y == 1)}\\n{self.zero_label} count : {np.count_nonzero(self.vec_y == 0)}')\n",
    "\n",
    "        \n",
    "class RnnDataObj:\n",
    "    def __init__(self,  X_df, labs,kmer_size,block_size, one_label, zero_label):\n",
    "        positive_cases=['all', 'stringtie-pacbio', 'scallop-pacbio']\n",
    "        X_df_labeled=pd.merge(left=labs, right=X_df, left_on='transcript_id', right_on='transcript_id')\n",
    "        X_data=np.asarray(X_df_labeled.iloc[:,3:])#drop the first 3 columns\n",
    "        \n",
    "        assert X_data.shape[1] % block_size == 0\n",
    "        block_dim=int(X_data.shape[1] / block_size)\n",
    "        X_data=np.asarray( [vec.reshape(block_size, block_dim) for vec in X_data])\n",
    "        Y_vec=np.asarray(X_df_labeled['target_label'])\n",
    "        \n",
    "        self.Y_origin=X_df_labeled.iloc[:,:3]\n",
    "        self.vec_y=Y_vec\n",
    "\n",
    "        X_train, self.X_val, Y_train_labs, Y_val_labs= train_test_split(X_data,labs,test_size=.2, random_state=42, stratify=Y_vec)\n",
    "        self.Y_val=to_categorical(Y_val_labs['target_label'])\n",
    "        self.Y_val_labs=Y_val_labs[['transcript_id','intersection_case']]\n",
    "        self.X_train, self.X_test, Y_train_labs, Y_test_labs=train_test_split(X_train,Y_train_labs,test_size=.2, \n",
    "                                                                              random_state=42,stratify=Y_train_labs['target_label'])\n",
    "        self.Y_train=to_categorical(Y_train_labs['target_label'])\n",
    "        self.Y_train_labs=Y_train_labs[['transcript_id','intersection_case']]\n",
    "        self.Y_test=to_categorical(Y_test_labs['target_label'])\n",
    "        self.Y_test_labs=Y_test_labs[['transcript_id','intersection_case']]\n",
    "\n",
    "        self.one_label=one_label\n",
    "        self.zero_label=zero_label\n",
    "    def summary(self):\n",
    "        tr_len=len(self.X_train)\n",
    "        ts_len=len(self.X_test)\n",
    "        v_len= len(self.X_val)\n",
    "        print(f'Training size: {tr_len}\\nvalidation size: {v_len}\\ntesting size: {ts_len}')\n",
    "        print(f'{self.one_label} count: {np.count_nonzero(self.vec_y == 1)}\\n{self.zero_label} count : {np.count_nonzero(self.vec_y == 0)}')\n",
    "        \n",
    "\n",
    "def model_results(Y_true, Y_pred_class, Y_pred_prob,kmer_size, edim, model_name, outdir):\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    data_name=[f'kmer={str(kmer_size)}_edim={str(edim)}_model={model_name}']\n",
    "    fpr, tpr, thresholds=roc_curve(Y_true, Y_pred_prob)\n",
    "    AUC=roc_auc_score(Y_true, Y_pred_class)\n",
    "    # Plot ROC curve\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % AUC)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "    pre, rec, thresholds = precision_recall_curve(Y_true, Y_pred_prob)\n",
    "    AUC = auc(rec, pre)\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(rec, pre, label=' Prec/Rec (area = %0.2f)' % ( AUC))\n",
    "    plt.plot([1, 1], [1, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall plot')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "    plt.suptitle(f'{data_name[0]} ROC and PRC')\n",
    "    #plt.show()\n",
    "    plt.savefig(outdir + data_name[0] + '_roc_prc.png' )\n",
    "    plt.close()\n",
    "    labs=['not_transcript', 'transcript'] \n",
    "    cr_dict=classification_report(y_pred=Y_pred_class, y_true=Y_true, output_dict=True)\n",
    "    data_name=[f'kmer={str(kmer_size)}_edim={str(edim)}_model={model_name}']\n",
    "    tm=['precision', 'recall','f1-score']\n",
    "    zero_line=[str(cr_dict['0'][key])  for key in tm]\n",
    "    one_line = [str(cr_dict['1'][key])  for key in tm]\n",
    "    accuracy=str(cr_dict['accuracy'])\n",
    "    out_cs_line= ','.join(data_name + zero_line + one_line +[accuracy]) + '\\n'\n",
    "    return(out_cs_line)\n",
    "\n",
    "def train_sk_model(dat, model):\n",
    "    model.fit(dat.X_train, dat.Y_train)\n",
    "    Y_pred_class=model.predict(dat.X_test)\n",
    "    Y_pred_prob=model.predict_proba(dat.X_test)[:,1]\n",
    "    return model, Y_pred_class, Y_pred_prob\n",
    "def train_tf_model(obj, model, batch_size, nepochs, model_name, outdir):\n",
    "    history=model.fit(obj.X_train, obj.Y_train, epochs=nepochs, batch_size=batch_size, \n",
    "            validation_data=(obj.X_val, obj.Y_val), verbose=0)\n",
    "    metrics =  ['loss', 'auc', 'accuracy']\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,3,n+1)\n",
    "        plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "                 color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.7,1])\n",
    "        else:\n",
    "            plt.ylim([0,1])\n",
    "\n",
    "        plt.legend()\n",
    "    plt.suptitle(f'{model_name} ROC and PRC')\n",
    "    plt.savefig(outdir + f'{model_name}_training_metrics.png')\n",
    "    plt.close()\n",
    "    pred=[p[1] for p in  model.predict(obj.X_test)]\n",
    "    pred_class = np.int64([p > .5 for p in pred])\n",
    "    true_class=[int(i[1]) for i in obj.Y_test]\n",
    "    return model, pred_class, pred\n",
    "METRICS = [keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),]\n",
    "def denseModel(edim):\n",
    "    model=keras.Sequential()\n",
    "    model.add(keras.layers.Dense(edim,activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "        \n",
    "    model.add(keras.layers.Dense(int(edim/4),  activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    \n",
    "    if edim > 300:\n",
    "        model.add(keras.layers.Dense(50,  activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dropout(.5))\n",
    "    \n",
    "    model.add(keras.layers.Dense(10,activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    \n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=METRICS)\n",
    "    return(model)\n",
    "def lstmDenseModel(input_dim):\n",
    "    NUM_UNITS=150\n",
    "    model=keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=input_dim))\n",
    "    model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=NUM_UNITS)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(150,activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(keras.layers.Dense(50,  activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=METRICS)\n",
    "\n",
    "    return(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_through_models(X_file_name, handle):\n",
    "    '''\n",
    "    load data in sklearn, tf, and rnn format\n",
    "    run each model through the data and \n",
    "        output f1,prec,rec, for each class, and accuracy\n",
    "    make plots and save\n",
    "    save model\n",
    "    '''\n",
    "    fn=X_file_name.split('/')[-1]\n",
    "    kmer_size=int(fn.split('_')[4])\n",
    "    edim=int(fn.split('_')[5].split('-')[1].split('.')[0])\n",
    "    one_label='transcript'\n",
    "    zero_label='not_transcript'\n",
    "    lab_file='testing/all_RPE_loose_target_tx.tsv'\n",
    "    #lab_file='data/gtf_info/all_RPE_loose_target_tx.tsv'\n",
    "    positive_cases=['all', 'stringtie-pacbio', 'scallop-pacbio']\n",
    "    mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    \n",
    "    out_dir=f'data/model_experiments/kmer-{str(kmer_size)}_edim-{str(edim)}/'\n",
    "    pathlib.Path(out_dir).mkdir(exist_ok=True)\n",
    "    X_df=pd.read_csv(X_file_name,names=['transcript_id']+ list(range(edim)))\n",
    "    labs=(pd\n",
    "        .read_csv(lab_file, sep= '\\t', names=['transcript_id', 'intersection_case'] )\n",
    "        .assign(target_label=lambda x: np.where(x['intersection_case'].isin(positive_cases),1,0 )) )\n",
    "    skl_obj=SimpleDataObj(X_df, labs, kmer_size, one_label, zero_label, 'sk')\n",
    "    rf_model=RandomForestClassifier(n_estimators=100, random_state=32, n_jobs=32)\n",
    "    rf_model_trained, rf_pred_class, rf_pred_prob=train_sk_model(skl_obj, rf_model)\n",
    "    rf_outline=model_results(skl_obj.Y_test, rf_pred_class, rf_pred_prob, kmer_size, edim,'random_forest', out_dir)\n",
    "    handle.write(rf_outline)\n",
    "    \n",
    "    wide_block_size = int(edim / 10)\n",
    "    long_block_size = 10\n",
    "    all_tf_data=[SimpleDataObj(X_df, labs, kmer_size, one_label, zero_label, 'tf'),\n",
    "                 RnnDataObj(X_df, labs,kmer_size,wide_block_size, one_label, zero_label),\n",
    "                 RnnDataObj(X_df, labs,kmer_size,long_block_size, one_label, zero_label)\n",
    "                ]\n",
    "    all_tf_models=[denseModel(edim),\n",
    "                lstmDenseModel(all_tf_data[1].X_train.shape[1:]),\n",
    "                lstmDenseModel(all_tf_data[2].X_train.shape[1:])\n",
    "               ]\n",
    "    tf_model_names=['Dense', 'LSTM-wide', 'LSTM-long']\n",
    "    dense_batch_size=int(all_tf_data[0].X_train.shape[0] / 8)\n",
    "    rnn_batch_size = int(all_tf_data[1].X_train.shape[0] / 128)\n",
    "    batch_sizes=[dense_batch_size,rnn_batch_size, rnn_batch_size ]\n",
    "    \n",
    "    for i in range(len(all_tf_data)) :\n",
    "        c_model=all_tf_models[i]\n",
    "        c_data=all_tf_data[i]\n",
    "        c_bs=batch_sizes[i]\n",
    "        c_model_name=tf_model_names[i]\n",
    "        trained_model, Y_pred_class, Y_pred_prob = train_tf_model(c_data, c_model, c_bs, 250, c_model_name, out_dir)\n",
    "        Y_true=[int(i[1]) for i in c_data.Y_test]\n",
    "        out_line=model_results(Y_true, Y_pred_class, Y_pred_prob, kmer_size, edim,c_model_name, out_dir)\n",
    "        handle.write(out_line)\n",
    "        c_model.save( f'{out_dir}{c_model_name}_trained.h5')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('testing/model_res.out', 'w+') as tout:\n",
    "#    run_data_through_models('testing/all_RPE_loose_kmers_8_dims-100.csv.gz', tout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/model_exp_results.csv', 'w+') as outfile:\n",
    "    all_files=glob.glob('data/embedded_model_data/*.csv.gz')\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            print()\n",
    "            #run_data_through_models(file, outfile)\n",
    "        except:\n",
    "            print(f'{file} failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
